---
title: "Distributed Thinking: A gentle introduction to distributed processing using Apache Storm and Apache Spark - Part 0" 
author: admin
layout: post
permalink: /2015/12/distributed-thinking-storm-spark-part0/
comments: true
categories:
  - Storm
  - Spark
  - Java
  - Scala
tags:
  - storm
  - spark
  - scala
  - java
  - distributed
  - big data
---

<img src="http://spark.apache.org/images/spark-logo-trademark.png" alt="Apache Spark Logo" style="height: 100"/><img src="http://storm.apache.org/images/logo.png" alt="Apache Storm Logo" style="height: 100"/>

<h1>0. Introduction</h1>

This post is meant to serve as a starting point for people using Java or Scala to process large amounts of data, and need a quick introduction to how to do it - either in Spark or in Storm.

It is not meant to be a Spark vs Storm debate, there are plenty of those out there. A quick Google search yields several [StackOverflow questions](http://stackoverflow.com/questions/24119897/apache-spark-vs-apache-storm) and technical [blogs](http://www.infoworld.com/article/2854894/application-development/spark-and-storm-for-real-time-computation.html) talking endlessly about it.

This is meant to be a starting point for people new to the whole concept of distributed processing of data, and need a headstart. It's 2015, and my blog post is probably 5 years too late, but it's never too late to get started!

<h3>What I plan to talk about:</h3>

1. Distributed Thinking
    1. When to use it?
    2. Where to start?
    3. How to look at data?
2. Processing Data Streams
3. Processing Large Data Chunks

-------------

Click here to go to the first part - [Distributed Thinking](/2016/01/distributed-thinking-storm-spark-part1 "Distributed Thinking")
